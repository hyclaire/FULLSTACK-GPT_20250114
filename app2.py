import streamlit as st
import time
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.callbacks.base import BaseCallbackHandler
from langchain.prompts import PromptTemplate
from langchain.callbacks.base import BaseCallbackHandler
import json

st.set_page_config(
    page_title="Streamlit is",
    page_icon="ğŸ¤–",
)

st.markdown(
    """
(EN)
Implement QuizGPT but add the following features:

Use function calling.
Allow the user to customize the difficulty of the test and make the LLM generate hard or easy questions.
Allow the user to retake the test if not all answers are correct.
If all answers are correct use st.ballons.
Allow the user to use its own OpenAI API Key, load it from an st.input inside of st.sidebar
Using st.sidebar put a link to the Github repo with the code of your Streamlit app.

(KR)
QuizGPTë¥¼ êµ¬í˜„í•˜ë˜ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

í•¨ìˆ˜ í˜¸ì¶œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ìœ ì €ê°€ ì‹œí—˜ì˜ ë‚œì´ë„ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§• í•  ìˆ˜ ìˆë„ë¡ í•˜ê³  LLMì´ ì–´ë ¤ìš´ ë¬¸ì œ ë˜ëŠ” ì‰¬ìš´ ë¬¸ì œë¥¼ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
ë§Œì ì´ ì•„ë‹Œ ê²½ìš° ìœ ì €ê°€ ì‹œí—˜ì„ ë‹¤ì‹œ ì¹˜ë¥¼ ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤.
ë§Œì ì´ë©´ st.ballonsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
ìœ ì €ê°€ ìì²´ OpenAI API í‚¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í—ˆìš©í•˜ê³ , st.sidebar ë‚´ë¶€ì˜ st.inputì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
st.sidebarë¥¼ ì‚¬ìš©í•˜ì—¬ Streamlit appì˜ ì½”ë“œì™€ í•¨ê»˜ Github ë¦¬í¬ì§€í† ë¦¬ì— ë§í¬ë¥¼ ë„£ìŠµë‹ˆë‹¤.

"""
)

def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})

#schema
function = {
    "name": "create_quiz",
    "description": "function that takes a list of questions and answers and returns a quiz",
    "parameters": {
        "type": "object",
        "properties": {
            "questions": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "question": {
                            "type": "string",
                        },
                        "answers": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "answer": {
                                        "type": "string",
                                    },
                                    "correct": {
                                        "type": "boolean",
                                    },
                                },
                                "required": ["answer", "correct"],
                            },
                        },
                    },
                    "required": ["question", "answers"],
                },
            }
        },
        "required": ["questions"],
    },
}

with st.sidebar:
    input_open_api_key = st.text_input("Please enter your Open API Key here")

if input_open_api_key :

    class ChatCallbackHandler(BaseCallbackHandler):
        # to make it look like the AI writes the answer itself

        message = ""
    
        def on_llm_start(self, *args, **kwargs):
            self.message_box = st.empty()
        def on_llm_end(self, *args, **kwargs):
            save_message(self.message, "ai")

        def on_llm_new_token(self, token, *args, **kwargs):
            self.message += token
            self.message_box.markdown(self.message)

    with st.sidebar:
        difficulty = st.selectbox(
        "Please select the difficulty of the test", ("Difficult", "Easy"), index=None, placeholder="Select the difficulty of the test...",
    )

    if difficulty:

        llm = ChatOpenAI(
            temperature = 0.1,
            streaming=True,
            callbacks=[
                ChatCallbackHandler(),
            ],
            openai_api_key = input_open_api_key,
        ).bind(
        function_call={
            "name": "create_quiz",
        },
        functions=[
            function,
        ],
    )
    # only work for gpt-3 and gpt-4

        #st.write(difficulty)
        prompt = PromptTemplate.from_template("Make a quiz about {city}." + "The difficulty level is " + difficulty)

        chain = prompt | llm

        response = chain.invoke({"city": "Seoul"})
        #st.balloons()

        response = response.additional_kwargs["function_call"]["arguments"]

        with st.form("questions_form"):
            correct_answer = 0
            total_questions = len(json.loads(response)["questions"])
            for question in json.loads(response)["questions"]:
                #print(question)
                st.write(question["question"]) #showing questions
                value = st.radio("Select an option.", [answer["answer"] for answer in question["answers"]], index=None)
                    #st.write(value)
                if {"answer" : value, "correct" : True} in question["answers"]:
                    st.success("Correct!")
                    correct_answer+=1
                elif value is not None:
                    st.error("Wrong..")
                    # check the answer
            button = st.form_submit_button("Submit")

            if button:
                st.session_state.submitted = True
                if correct_answer == total_questions:
                    st.balloons()

